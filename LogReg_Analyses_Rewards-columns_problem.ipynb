{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "This logistic regression is based on the Beeler/Daw et al. 2010 paper.\n",
    "Specifically:\n",
    "\n",
    "dependent variable: binary choice of port (-1 or 1)\n",
    "\n",
    "explanatory variables: \n",
    "1. the N previous rewards $ r_{t-N:t-1} $\n",
    "2. the previous choice $c_{t-1}$ to capture a tendency to stay or switch\n",
    "3. bias variable (1) to capture fixed, overall preference for either port\n",
    "\n",
    "Note: this model only carries information about ports when it gets a reward. IE -1 = right reward, 1 = left reward, but 0 = no reward (for either side). Should compare models with this information vs. added information about the non-rewarded port choices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02/19/2017\n",
    "I just ran the above code on the following data:\n",
    "    \n",
    "- `full_9010_02192017.csv`\n",
    "- `full_8020_02192017.csv`\n",
    "- `full_7030_02192017.csv`\n",
    "\n",
    "Which were computed by compiling the following data:\n",
    "- block range: exactly 50 rewards\n",
    "- p(choose high Port) >= [p-0.1] where p = p(high Port)\n",
    "\n",
    "Observations:\n",
    "1. pseudo-R2 also similar: ~0.64-0.69\n",
    "2. For (1)  maybe a slight trend that 90-10 had a better model, but not certain. \n",
    "3. For each condition, I tried adding in more ports (up to 3) into the past to see if it would help out. For all 3 conditions, decisions for t-N where 2 >= 2 had coefficients = 0. That is, the only non-zero beta for the ports was the most recent one. \n",
    "\n",
    "Next step: \n",
    "\n",
    "\n",
    "**Figures**\n",
    "\n",
    "1. Logistic regression performs similarly across different conditions\n",
    "    - x axis: 90-10,80-20,70-30\n",
    "    - y axis: F1 score, pseudo-R2\n",
    "2. Comparing model flexibility across different conditions\n",
    "    - x axis: number of previous rewards included (i.e. parameters in model)\n",
    "    - y axis: BIC\n",
    "    - color: each condition\n",
    "3. Knowing where the non-rewarded trials are:\n",
    "    - what if you did the same regression, but instead you know where the non-rewarded trials are?\n",
    "    - also, compare to adding in previous ports (or rewards in the above scenario) and compare\n",
    "\n",
    "4. Comparing 'strategies' across conditions\n",
    "    - train on 90-10, test on 80-20 (and all combinations)\n",
    "\n",
    "5. Comparing 'strategies' across mice\n",
    "    - train on one mouse:condition pair, and test on another mouse:condition pair (for the same condition)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/Sabatini Lab/GitHub/mouse_bandit/data_preprocessing_code')\n",
    "sys.path.append('/Users/Sabatini Lab/GitHub/mouse_bandit')\n",
    "import support_functions as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import bandit_preprocessing as bp\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "import statsmodels\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function to do logistic regression and some basic evalutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I compiled the code above into a more compact function so I can cycle through different conditions/mice/etc \n",
    "as neccessary\n",
    "'''\n",
    "\n",
    "def logreg_and_eval(data,num_rewards=10,test_data=False):\n",
    "    '''\n",
    "    Perform Logistic Regression on a pandas dataframe of trials (from feature matrix)\n",
    "    \n",
    "    Inputs:\n",
    "        - data: pandas dataframe of trials (from feature matrix)\n",
    "    Outputs:\n",
    "        - logreg: trained logistic regression model (from sklearn)\n",
    "        - stats:  pandas dataframe with F1, pseudo-R2, and BIC scores from model\n",
    "        - coeffs: beta coefficients from logreg\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    from statsmodels.discrete.discrete_model import Logit\n",
    "    \n",
    "    port_features = []\n",
    "    reward_features = []\n",
    "\n",
    "    #change right port to -1 instead of 0\n",
    "    for col in data:\n",
    "        if '_Port' in col:\n",
    "            data.loc[data[col] == 0,col] = -1\n",
    "            port_features.append(col)\n",
    "        elif '_Reward' in col:\n",
    "            reward_features.append(col)\n",
    "\n",
    "    #create new feature matrix\n",
    "    d = data.copy()\n",
    "    for i in range(len(port_features)):\n",
    "        d[reward_features[i]] = d[reward_features[i]].values*d[port_features[i]].values\n",
    "    \n",
    "    \n",
    "    #determine the features\n",
    "    features = reward_features.copy()\n",
    "    features = features[-1*num_rewards:] #only take the num of rewards specificied in the function\n",
    "    features.append('1_Port') #append the last decision as a feature\n",
    "    features.append('Decision') #finally append the decision so we can take it to predict later\n",
    "    \n",
    "    #final version of data\n",
    "    d = d[features].copy() #this now just has the features we want and the decision we want to predict\n",
    "    \n",
    "    #do the same thing for the test data if it exists!\n",
    "    if test_data is not False:\n",
    "        for col in test_data:\n",
    "            if '_Port' in col:\n",
    "                test_data.loc[test_data[col] == 0,col] = -1\n",
    "\n",
    "        #create new feature matrix\n",
    "        data_test_new = test_data.copy()\n",
    "        for i in range(len(port_features)):\n",
    "            data_test_new[reward_features[i]] = test_data[reward_features[i]].values*test_data[port_features[i]].values\n",
    "        \n",
    "        d_test = data_test_new[features].copy()\n",
    "    \n",
    "    \n",
    "        #set training and testing sets now\n",
    "        x_train = d.iloc[:,:-1].values\n",
    "        y_train = d.iloc[:,-1].values\n",
    "        x_test = d_test.iloc[:,:-1].values\n",
    "        y_test = d_test.iloc[:,-1].values\n",
    "        \n",
    "        prev_port_test = d_test['1_Port'].values\n",
    "        prev_port_test[prev_port_test==-1] = 0\n",
    "    \n",
    "    #if there is no test data, then split up the data into training and testing\n",
    "    else:\n",
    "        #extract features and decisions\n",
    "        x = d.iloc[:,:-1].values\n",
    "        y = d.iloc[:,-1].values\n",
    "\n",
    "        #split into training and testing\n",
    "        n_trials = x.shape[0]\n",
    "        shuf_inds = np.random.permutation(n_trials)\n",
    "        split_ind = int(n_trials*0.7)\n",
    "\n",
    "        x_train = x[shuf_inds[:split_ind],:]\n",
    "        y_train = y[shuf_inds[:split_ind]]\n",
    "\n",
    "        x_test = x[shuf_inds[split_ind:],:]\n",
    "        y_test = y[shuf_inds[split_ind:]]\n",
    "        \n",
    "        #extract previous port decision for test set\n",
    "        #these will be used to calculate switches on the test predictions\n",
    "        prev_port_test = d['1_Port'].values[shuf_inds[split_ind:]]\n",
    "        prev_port_test[prev_port_test==-1] = 0\n",
    "    \n",
    "    '''\n",
    "    Modeling\n",
    "    '''\n",
    "    \n",
    "    #fit logistic regression\n",
    "    logreg = sklearn.linear_model.LogisticRegressionCV()\n",
    "    logreg.fit(x_train,y_train)\n",
    "    \n",
    "    #predict on testing set\n",
    "    y_predict = logreg.predict(x_test)\n",
    "    y_predict_proba = logreg.predict_proba(x_test)\n",
    "    \n",
    "    #model accuracy\n",
    "    score = logreg.score(x_test,y_test)\n",
    "    \n",
    "    #calculating pseudo-R2 and BIC from statsmodel OLS\n",
    "    model = Logit(y_train,x_train)\n",
    "    rslt  = model.fit()\n",
    "\n",
    "    #switches\n",
    "    y_test_switch = np.abs(y_test - prev_port_test)\n",
    "    y_predict_switch = np.abs(y_predict - prev_port_test)\n",
    "    acc_pos,acc_neg,F1=sf.score_both_and_confuse(y_predict_switch,y_test_switch,confusion=False,disp=True)\n",
    "    \n",
    "    #extract coefficients\n",
    "    coefs = logreg.coef_ #retrieve coefs\n",
    "    coefs = np.append(coefs[0],logreg.intercept_) #add bias coef\n",
    "    \n",
    "    #create stats database to return\n",
    "    d_ = {'pseudo-R2':rslt.prsquared,'stay':acc_pos,'switch':acc_neg,'Accuracy':score,\n",
    "          'BIC':rslt.bic,'negative loglikelihood':-1*rslt.llf,'F1':F1}\n",
    "    stats = pd.DataFrame(data=d_,index=[0])\n",
    "    features = features[:-1]\n",
    "    features.append('Bias')\n",
    "    \n",
    "    coefs = pd.DataFrame(data=coefs.reshape(1,-1),columns=features)\n",
    "    return logreg,stats,coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logreg_and_eval_withports(data,num_rewards=10,num_ports=1,test_data=False):\n",
    "    '''\n",
    "    Perform Logistic Regression on a pandas dataframe of trials (from feature matrix)\n",
    "    \n",
    "    Inputs:\n",
    "        - data: pandas dataframe of trials (from feature matrix)\n",
    "    Outputs:\n",
    "        - logreg: trained logistic regression model (from sklearn)\n",
    "        - stats:  pandas dataframe with F1, pseudo-R2, and BIC scores from model\n",
    "        - coeffs: beta coefficients from logreg\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    from statsmodels.discrete.discrete_model import Logit\n",
    "    \n",
    "    port_features = []\n",
    "    reward_features = []\n",
    "\n",
    "    #change right port to -1 instead of 0\n",
    "    for col in data:\n",
    "        if '_Port' in col:\n",
    "            data.loc[data[col] == 0,col] = -1\n",
    "            port_features.append(col)\n",
    "        elif '_Reward' in col:\n",
    "            reward_features.append(col)\n",
    "\n",
    "    #create new feature matrix\n",
    "    d = data.copy()\n",
    "    for i in range(len(port_features)):\n",
    "        d[reward_features[i]] = d[reward_features[i]].values*d[port_features[i]].values\n",
    "    \n",
    "    \n",
    "    #determine the features\n",
    "    features = reward_features.copy()\n",
    "    if num_rewards == 0:\n",
    "        features = port_features[-1*num_ports:]\n",
    "    elif num_ports == 0:\n",
    "        features = features[-1*num_rewards:] #only take the num of rewards specificied in the function\n",
    "    else:\n",
    "        features = features[-1*num_rewards:]\n",
    "        features = np.append(features,port_features[-1*num_ports:])\n",
    "    \n",
    "    print(features)\n",
    "    features = np.append(features,'Decision') #finally append the decision so we can take it to predict later\n",
    "    \n",
    "    \n",
    "    \n",
    "    #final version of data\n",
    "    d = d[features].copy() #this now just has the features we want and the decision we want to predict\n",
    "    \n",
    "    #do the same thing for the test data if it exists!\n",
    "    if test_data is not False:\n",
    "        for col in test_data:\n",
    "            if '_Port' in col:\n",
    "                test_data.loc[test_data[col] == 0,col] = -1\n",
    "\n",
    "        #create new feature matrix\n",
    "        data_test_new = test_data.copy()\n",
    "        for i in range(len(port_features)):\n",
    "            data_test_new[reward_features[i]] = test_data[reward_features[i]].values*test_data[port_features[i]].values\n",
    "        \n",
    "        d_test = data_test_new[features].copy()\n",
    "    \n",
    "    \n",
    "        #set training and testing sets now\n",
    "        x_train = d.iloc[:,:-1].values\n",
    "        y_train = d.iloc[:,-1].values\n",
    "        x_test = d_test.iloc[:,:-1].values\n",
    "        y_test = d_test.iloc[:,-1].values\n",
    "        \n",
    "        prev_port_test = test_data['1_Port'].values\n",
    "        prev_port_test[prev_port_test==-1] = 0\n",
    "    \n",
    "    #if there is no test data, then split up the data into training and testing\n",
    "    else:\n",
    "        #extract features and decisions\n",
    "        x = d.iloc[:,:-1].values\n",
    "        y = d.iloc[:,-1].values\n",
    "\n",
    "        #split into training and testing\n",
    "        n_trials = x.shape[0]\n",
    "        shuf_inds = np.random.permutation(n_trials)\n",
    "        split_ind = int(n_trials*0.7)\n",
    "\n",
    "        x_train = x[shuf_inds[:split_ind],:]\n",
    "        y_train = y[shuf_inds[:split_ind]]\n",
    "\n",
    "        x_test = x[shuf_inds[split_ind:],:]\n",
    "        y_test = y[shuf_inds[split_ind:]]\n",
    "        \n",
    "        #extract previous port decision for test set\n",
    "        #these will be used to calculate switches on the test predictions\n",
    "        prev_port_test = data['1_Port'].values[shuf_inds[split_ind:]]\n",
    "        prev_port_test[prev_port_test==-1] = 0\n",
    "    \n",
    "    '''\n",
    "    Modeling\n",
    "    '''\n",
    "    \n",
    "    #fit logistic regression\n",
    "    logreg = sklearn.linear_model.LogisticRegressionCV()\n",
    "    logreg.fit(x_train,y_train)\n",
    "    \n",
    "    #predict on testing set\n",
    "    y_predict = logreg.predict(x_test)\n",
    "    y_predict_proba = logreg.predict_proba(x_test)\n",
    "    \n",
    "    #model accuracy\n",
    "    score = logreg.score(x_test,y_test)\n",
    "    \n",
    "    #calculating pseudo-R2 and BIC from statsmodel OLS\n",
    "    model = Logit(y_train,x_train)\n",
    "    rslt  = model.fit()\n",
    "\n",
    "    #switches\n",
    "    y_test_switch = np.abs(y_test - prev_port_test)\n",
    "    y_predict_switch = np.abs(y_predict - prev_port_test)\n",
    "    acc_pos,acc_neg,F1=sf.score_both_and_confuse(y_predict_switch,y_test_switch,confusion=False,disp=True)\n",
    "    \n",
    "    #extract coefficients\n",
    "    coefs = logreg.coef_ #retrieve coefs\n",
    "    coefs = np.append(coefs[0],logreg.intercept_) #add bias coef\n",
    "    \n",
    "    #create stats database to return\n",
    "    d_ = {'pseudo-R2':rslt.prsquared,'stay':acc_pos,'switch':acc_neg,'Accuracy':score,\n",
    "          'BIC':rslt.bic,'negative loglikelihood':-1*rslt.llf,'F1':F1}\n",
    "    stats = pd.DataFrame(data=d_,index=[0])\n",
    "    features = features[:-1]\n",
    "    features = np.append(features,'Bias')\n",
    "    \n",
    "    coefs = pd.DataFrame(data=coefs.reshape(1,-1),columns=features)\n",
    "    return logreg,stats,coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_90 = pd.read_csv('/Users/Sabatini Lab/GitHub/mouse_bandit/data/mike_data/trial_data/all_9010_high.csv',index_col=0)\n",
    "#data_90 = pd.read_csv('/Users/Sabatini Lab/GitHub/mouse_bandit/data/processed_data/full_9010_02192017.csv',index_col=0)\n",
    "\n",
    "datas = [data_90]\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    Mouse ID      Session ID  Trial  Block Trial  Block Reward  Port Streak  \\\n",
       " 0      SOM42  06142017_SOM42   11.0         11.0           7.0          2.0   \n",
       " 1      SOM42  06142017_SOM42   12.0         12.0           8.0          3.0   \n",
       " 2      SOM42  06142017_SOM42   13.0         13.0           9.0          4.0   \n",
       " 3      SOM42  06142017_SOM42   14.0         14.0          10.0          5.0   \n",
       " 4      SOM42  06142017_SOM42   15.0         15.0          11.0          6.0   \n",
       " 5      SOM42  06142017_SOM42   16.0         16.0          12.0          7.0   \n",
       " 6      SOM42  06142017_SOM42   17.0         17.0          13.0          8.0   \n",
       " 7      SOM42  06142017_SOM42   18.0         18.0          14.0          9.0   \n",
       " 8      SOM42  06142017_SOM42   19.0         19.0          15.0         10.0   \n",
       " 9      SOM42  06142017_SOM42   20.0         20.0          16.0         11.0   \n",
       " 10     SOM42  06142017_SOM42   21.0         21.0          17.0         12.0   \n",
       " 11     SOM42  06142017_SOM42   22.0         22.0          18.0         13.0   \n",
       " 12     SOM42  06142017_SOM42   23.0         23.0          19.0         14.0   \n",
       " 13     SOM42  06142017_SOM42   24.0         24.0          19.0         15.0   \n",
       " 14     SOM42  06142017_SOM42   25.0         25.0          20.0         16.0   \n",
       " 15     SOM42  06142017_SOM42   26.0         26.0          21.0         17.0   \n",
       " 16     SOM42  06142017_SOM42   27.0         27.0          22.0         18.0   \n",
       " 17     SOM42  06142017_SOM42   28.0         28.0          23.0         19.0   \n",
       " 18     SOM42  06142017_SOM42   29.0         29.0          24.0         20.0   \n",
       " 19     SOM42  06142017_SOM42   30.0         30.0          25.0         21.0   \n",
       " 20     SOM42  06142017_SOM42   31.0         31.0          26.0         22.0   \n",
       " 21     SOM42  06142017_SOM42   32.0         32.0          27.0         23.0   \n",
       " 22     SOM42  06142017_SOM42   33.0         33.0          28.0         24.0   \n",
       " 23     SOM42  06142017_SOM42   34.0         34.0          29.0         25.0   \n",
       " 24     SOM42  06142017_SOM42   35.0         35.0          30.0         26.0   \n",
       " 25     SOM42  06142017_SOM42   36.0         36.0          31.0         27.0   \n",
       " 26     SOM42  06142017_SOM42   37.0         37.0          32.0         28.0   \n",
       " 27     SOM42  06142017_SOM42   38.0         38.0          33.0         29.0   \n",
       " 28     SOM42  06142017_SOM42   39.0         39.0          34.0         30.0   \n",
       " 29     SOM42  06142017_SOM42   40.0         40.0          35.0         31.0   \n",
       " ..       ...             ...    ...          ...           ...          ...   \n",
       " 425    SOM45  07202017_SOM45  436.0         13.0           8.0          8.0   \n",
       " 426    SOM45  07202017_SOM45  437.0         14.0           9.0          9.0   \n",
       " 427    SOM45  07202017_SOM45  438.0         15.0          10.0         10.0   \n",
       " 428    SOM45  07202017_SOM45  439.0         16.0          11.0         11.0   \n",
       " 429    SOM45  07202017_SOM45  440.0         17.0          12.0         12.0   \n",
       " 430    SOM45  07202017_SOM45  441.0         18.0          13.0         13.0   \n",
       " 431    SOM45  07202017_SOM45  442.0         19.0          13.0         14.0   \n",
       " 432    SOM45  07202017_SOM45  443.0         20.0          13.0          1.0   \n",
       " 433    SOM45  07202017_SOM45  444.0         21.0          13.0          2.0   \n",
       " 434    SOM45  07202017_SOM45  445.0         22.0          14.0          1.0   \n",
       " 435    SOM45  07202017_SOM45  446.0         23.0          15.0          2.0   \n",
       " 436    SOM45  07202017_SOM45  447.0         24.0          15.0          1.0   \n",
       " 437    SOM45  07202017_SOM45  448.0         25.0          16.0          1.0   \n",
       " 438    SOM45  07202017_SOM45  449.0         26.0          16.0          1.0   \n",
       " 439    SOM45  07202017_SOM45  450.0         27.0          16.0          2.0   \n",
       " 440    SOM45  07202017_SOM45  451.0         28.0          16.0          3.0   \n",
       " 441    SOM45  07202017_SOM45  452.0         29.0          17.0          4.0   \n",
       " 442    SOM45  07202017_SOM45  453.0         30.0          18.0          5.0   \n",
       " 443    SOM45  07202017_SOM45  454.0         31.0          18.0          6.0   \n",
       " 444    SOM45  07202017_SOM45  455.0         32.0          18.0          7.0   \n",
       " 445    SOM45  07202017_SOM45  456.0         33.0          19.0          1.0   \n",
       " 446    SOM45  07202017_SOM45  457.0         34.0          20.0          2.0   \n",
       " 447    SOM45  07202017_SOM45  458.0         35.0          21.0          1.0   \n",
       " 448    SOM45  07202017_SOM45  459.0         36.0          21.0          2.0   \n",
       " 449    SOM45  07202017_SOM45  460.0         37.0          21.0          3.0   \n",
       " 450    SOM45  07202017_SOM45  461.0         38.0          21.0          4.0   \n",
       " 451    SOM45  07202017_SOM45  462.0         39.0          22.0          1.0   \n",
       " 452    SOM45  07202017_SOM45  463.0         40.0          23.0          2.0   \n",
       " 453    SOM45  07202017_SOM45  464.0         41.0          24.0          3.0   \n",
       " 454    SOM45  07202017_SOM45  465.0         42.0          25.0          4.0   \n",
       " \n",
       "      Reward Streak  10_Port  10_Reward  10_ITI   ...    1_Port  1_Reward  \\\n",
       " 0             -1.0    0.426        0.0     1.0   ...     0.488       0.0   \n",
       " 1              1.0    0.411        0.0     1.0   ...     0.355       0.0   \n",
       " 2              2.0    0.414        0.0     1.0   ...     0.426       0.0   \n",
       " 3              3.0    0.394        0.0     1.0   ...     0.411       0.0   \n",
       " 4              4.0    0.418        0.0     1.0   ...     0.414       0.0   \n",
       " 5              5.0    0.405        0.0     1.0   ...     0.394       0.0   \n",
       " 6              6.0    0.523        1.0     0.0   ...     0.418       0.0   \n",
       " 7              7.0    0.415        1.0     0.0   ...     0.405       0.0   \n",
       " 8              8.0    0.463        0.0     1.0   ...     0.523       0.0   \n",
       " 9              9.0    0.636        0.0     0.0   ...     0.415       0.0   \n",
       " 10            10.0    0.400        0.0     1.0   ...     0.463       0.0   \n",
       " 11            11.0    0.372        0.0     1.0   ...     0.636       0.0   \n",
       " 12            12.0    0.374        0.0     1.0   ...     0.400       0.0   \n",
       " 13            -1.0    0.419        0.0     1.0   ...     0.372       0.0   \n",
       " 14             1.0    0.395        0.0     1.0   ...     0.374       0.0   \n",
       " 15             2.0    0.524        0.0     1.0   ...     0.419       0.0   \n",
       " 16             3.0    0.436        0.0     1.0   ...     0.395       0.0   \n",
       " 17             4.0    0.417        0.0     1.0   ...     0.524       0.0   \n",
       " 18             5.0    0.423        0.0     1.0   ...     0.436       0.0   \n",
       " 19             6.0    0.415        0.0     1.0   ...     0.417       0.0   \n",
       " 20             7.0    0.431        0.0     1.0   ...     0.423       0.0   \n",
       " 21             8.0    0.399        0.0     1.0   ...     0.415       0.0   \n",
       " 22             9.0    0.415        0.0     0.0   ...     0.431       0.0   \n",
       " 23            10.0    0.435        0.0     1.0   ...     0.399       0.0   \n",
       " 24            11.0    0.422        0.0     1.0   ...     0.415       0.0   \n",
       " 25            12.0    0.372        0.0     1.0   ...     0.435       0.0   \n",
       " 26            13.0    0.418        0.0     1.0   ...     0.422       0.0   \n",
       " 27            14.0    0.353        0.0     1.0   ...     0.372       0.0   \n",
       " 28            15.0    0.449        0.0     1.0   ...     0.418       0.0   \n",
       " 29            16.0    0.397        0.0     1.0   ...     0.353       0.0   \n",
       " ..             ...      ...        ...     ...   ...       ...       ...   \n",
       " 425            8.0    0.369        1.0     0.0   ...     0.526       0.0   \n",
       " 426            9.0    0.563        1.0     0.0   ...     0.507       0.0   \n",
       " 427           10.0    1.548        0.0     1.0   ...     0.369       0.0   \n",
       " 428           11.0    0.561        0.0     1.0   ...     0.563       0.0   \n",
       " 429           12.0    0.514        0.0     1.0   ...     1.548       0.0   \n",
       " 430           13.0    0.352        0.0     1.0   ...     0.561       0.0   \n",
       " 431           -1.0    0.426        0.0     1.0   ...     0.514       0.0   \n",
       " 432           -2.0    0.453        0.0     1.0   ...     0.352       1.0   \n",
       " 433           -3.0    0.497        0.0     1.0   ...     0.426       1.0   \n",
       " 434            1.0    0.523        0.0     1.0   ...     0.453       0.0   \n",
       " 435            2.0    1.272        0.0     1.0   ...     0.497       0.0   \n",
       " 436           -1.0    0.979        0.0     1.0   ...     0.523       1.0   \n",
       " 437            1.0    0.582        0.0     1.0   ...     1.272       0.0   \n",
       " 438           -1.0    0.574        0.0     1.0   ...     0.979       1.0   \n",
       " 439           -2.0    0.536        0.0     1.0   ...     0.582       1.0   \n",
       " 440           -3.0    0.385        0.0     0.0   ...     0.574       1.0   \n",
       " 441            1.0    0.406        1.0     0.0   ...     0.536       1.0   \n",
       " 442            2.0    0.334        1.0     0.0   ...     0.385       1.0   \n",
       " 443           -1.0    0.450        0.0     1.0   ...     0.406       1.0   \n",
       " 444           -2.0    0.506        0.0     1.0   ...     0.334       1.0   \n",
       " 445            1.0    0.417        1.0     0.0   ...     0.450       0.0   \n",
       " 446            2.0    0.554        0.0     1.0   ...     0.506       0.0   \n",
       " 447            3.0    0.295        1.0     0.0   ...     0.417       1.0   \n",
       " 448           -1.0    0.366        1.0     0.0   ...     0.554       1.0   \n",
       " 449           -2.0    0.449        1.0     0.0   ...     0.295       1.0   \n",
       " 450           -3.0    0.456        1.0     1.0   ...     0.366       1.0   \n",
       " 451            1.0    0.354        1.0     1.0   ...     0.449       0.0   \n",
       " 452            2.0    0.867        1.0     0.0   ...     0.456       0.0   \n",
       " 453            3.0    0.358        1.0     0.0   ...     0.354       0.0   \n",
       " 454            4.0    0.362        0.0     1.0   ...     0.867       0.0   \n",
       " \n",
       "      1_ITI  1_trialDuration  0_ITI  0_trialDuration  Decision  Switch  \\\n",
       " 0      0.0            4.024  0.355            2.052       0.0     0.0   \n",
       " 1      1.0            2.052  0.426            3.879       0.0     0.0   \n",
       " 2      1.0            3.879  0.411            3.514       0.0     0.0   \n",
       " 3      1.0            3.514  0.414            2.229       0.0     0.0   \n",
       " 4      1.0            2.229  0.394            3.317       0.0     0.0   \n",
       " 5      1.0            3.317  0.418            4.422       0.0     0.0   \n",
       " 6      1.0            4.422  0.405            5.116       0.0     0.0   \n",
       " 7      1.0            5.116  0.523            4.748       0.0     0.0   \n",
       " 8      1.0            4.748  0.415            3.984       0.0     0.0   \n",
       " 9      1.0            3.984  0.463            1.597       0.0     0.0   \n",
       " 10     1.0            1.597  0.636            3.273       0.0     0.0   \n",
       " 11     1.0            3.273  0.400            3.408       0.0     0.0   \n",
       " 12     1.0            3.408  0.372            4.899       0.0     0.0   \n",
       " 13     0.0            4.899  0.374            2.333       0.0     0.0   \n",
       " 14     1.0            2.333  0.419            3.886       0.0     0.0   \n",
       " 15     1.0            3.886  0.395            6.874       0.0     0.0   \n",
       " 16     1.0            6.874  0.524            2.938       0.0     0.0   \n",
       " 17     1.0            2.938  0.436            4.469       0.0     0.0   \n",
       " 18     1.0            4.469  0.417            3.249       0.0     0.0   \n",
       " 19     1.0            3.249  0.423            4.617       0.0     0.0   \n",
       " 20     1.0            4.617  0.415            3.858       0.0     0.0   \n",
       " 21     1.0            3.858  0.431            2.054       0.0     0.0   \n",
       " 22     1.0            2.054  0.399            3.115       0.0     0.0   \n",
       " 23     1.0            3.115  0.415            3.577       0.0     0.0   \n",
       " 24     1.0            3.577  0.435            4.311       0.0     0.0   \n",
       " 25     1.0            4.311  0.422            3.449       0.0     0.0   \n",
       " 26     1.0            3.449  0.372            4.120       0.0     0.0   \n",
       " 27     1.0            4.120  0.418            3.582       0.0     0.0   \n",
       " 28     1.0            3.582  0.353            5.572       0.0     0.0   \n",
       " 29     1.0            5.572  0.449            3.537       0.0     0.0   \n",
       " ..     ...              ...    ...              ...       ...     ...   \n",
       " 425    1.0            1.501  0.507            1.283       0.0     0.0   \n",
       " 426    1.0            1.283  0.369            1.589       0.0     0.0   \n",
       " 427    1.0            1.589  0.563            1.653       0.0     0.0   \n",
       " 428    1.0            1.653  1.548            1.697       0.0     0.0   \n",
       " 429    1.0            1.697  0.561            1.146       0.0     0.0   \n",
       " 430    1.0            1.146  0.514            1.284       0.0     0.0   \n",
       " 431    0.0            1.284  0.352            2.975       1.0     1.0   \n",
       " 432    0.0            2.975  0.426            4.207       1.0     0.0   \n",
       " 433    0.0            4.207  0.453            1.495       0.0     1.0   \n",
       " 434    1.0            1.495  0.497            2.817       0.0     0.0   \n",
       " 435    1.0            2.817  0.523            1.461       1.0     1.0   \n",
       " 436    0.0            1.461  1.272           29.103       0.0     1.0   \n",
       " 437    1.0           29.103  0.979           71.619       1.0     1.0   \n",
       " 438    0.0           71.619  0.582            1.974       1.0     0.0   \n",
       " 439    0.0            1.974  0.574            1.365       1.0     0.0   \n",
       " 440    0.0            1.365  0.536           57.595       1.0     0.0   \n",
       " 441    1.0           57.595  0.385            1.726       1.0     0.0   \n",
       " 442    1.0            1.726  0.406            1.551       1.0     0.0   \n",
       " 443    0.0            1.551  0.334            1.146       1.0     0.0   \n",
       " 444    0.0            1.146  0.450            1.576       0.0     1.0   \n",
       " 445    1.0            1.576  0.506            2.527       0.0     0.0   \n",
       " 446    1.0            2.527  0.417           10.245       1.0     1.0   \n",
       " 447    1.0           10.245  0.554            1.471       1.0     0.0   \n",
       " 448    0.0            1.471  0.295            1.665       1.0     0.0   \n",
       " 449    0.0            1.665  0.366            1.372       1.0     0.0   \n",
       " 450    0.0            1.372  0.449            1.537       0.0     1.0   \n",
       " 451    1.0            1.537  0.456            2.388       0.0     0.0   \n",
       " 452    1.0            2.388  0.354            1.679       0.0     0.0   \n",
       " 453    1.0            1.679  0.867            1.280       0.0     0.0   \n",
       " 454    1.0            1.280  0.358            1.763       0.0     0.0   \n",
       " \n",
       "      Higher p port  Reward  \n",
       " 0              1.0     1.0  \n",
       " 1              1.0     1.0  \n",
       " 2              1.0     1.0  \n",
       " 3              1.0     1.0  \n",
       " 4              1.0     1.0  \n",
       " 5              1.0     1.0  \n",
       " 6              1.0     1.0  \n",
       " 7              1.0     1.0  \n",
       " 8              1.0     1.0  \n",
       " 9              1.0     1.0  \n",
       " 10             1.0     1.0  \n",
       " 11             1.0     1.0  \n",
       " 12             1.0     0.0  \n",
       " 13             1.0     1.0  \n",
       " 14             1.0     1.0  \n",
       " 15             1.0     1.0  \n",
       " 16             1.0     1.0  \n",
       " 17             1.0     1.0  \n",
       " 18             1.0     1.0  \n",
       " 19             1.0     1.0  \n",
       " 20             1.0     1.0  \n",
       " 21             1.0     1.0  \n",
       " 22             1.0     1.0  \n",
       " 23             1.0     1.0  \n",
       " 24             1.0     1.0  \n",
       " 25             1.0     1.0  \n",
       " 26             1.0     1.0  \n",
       " 27             1.0     1.0  \n",
       " 28             1.0     1.0  \n",
       " 29             1.0     1.0  \n",
       " ..             ...     ...  \n",
       " 425            1.0     1.0  \n",
       " 426            1.0     1.0  \n",
       " 427            1.0     1.0  \n",
       " 428            1.0     1.0  \n",
       " 429            1.0     1.0  \n",
       " 430            1.0     0.0  \n",
       " 431            0.0     0.0  \n",
       " 432            0.0     0.0  \n",
       " 433            1.0     1.0  \n",
       " 434            1.0     1.0  \n",
       " 435            0.0     0.0  \n",
       " 436            1.0     1.0  \n",
       " 437            0.0     0.0  \n",
       " 438            0.0     0.0  \n",
       " 439            0.0     0.0  \n",
       " 440            0.0     1.0  \n",
       " 441            0.0     1.0  \n",
       " 442            0.0     0.0  \n",
       " 443            0.0     0.0  \n",
       " 444            1.0     1.0  \n",
       " 445            1.0     1.0  \n",
       " 446            0.0     1.0  \n",
       " 447            0.0     0.0  \n",
       " 448            0.0     0.0  \n",
       " 449            0.0     0.0  \n",
       " 450            1.0     1.0  \n",
       " 451            1.0     1.0  \n",
       " 452            1.0     1.0  \n",
       " 453            1.0     1.0  \n",
       " 454            1.0     1.0  \n",
       " \n",
       " [35299 rows x 53 columns]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.313076\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sabatini Lab\\Anaconda3\\envs\\behavior\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Sabatini Lab\\Anaconda3\\envs\\behavior\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.311025\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.310077\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.311598\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.308363\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.313036\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.313297\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.313276\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.311176\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.318761\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.312985\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.310004\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.310301\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.310994\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.313519\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.310204\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.309811\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.310880\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.310183\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.311643\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.312903\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.315641\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.311380\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.312433\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.313783\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.309290\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.313303\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.308441\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            1.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: 1.00\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.311724\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.314450\n",
      "         Iterations 7\n",
      "          Predicted NO  Predicted YES\n",
      "True NO            0.0            0.0\n",
      "True YES           0.0            0.0\n",
      "\n",
      "F1: 0.000\n",
      "\n",
      "Accuracy on class 0: nan\n",
      "Accuracy on class 1: nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,d in enumerate(datas):\n",
    "    \n",
    "    for j in range(30):\n",
    "        model_curr,stats_curr,coefs_curr = logreg_and_eval(d,num_rewards=7)\n",
    "        models.append(models)\n",
    "\n",
    "        if ((i == 0 and j == 0)):\n",
    "            stats = stats_curr.copy()\n",
    "            coefs = coefs_curr.copy()\n",
    "        else:\n",
    "            stats = stats.append(stats_curr)\n",
    "            coefs = coefs.append(coefs_curr)\n",
    "\n",
    "c = np.zeros(30)+90\n",
    "\n",
    "\n",
    "stats.insert(0,'Condition',c)\n",
    "coefs.insert(0,'Condition',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>BIC</th>\n",
       "      <th>F1</th>\n",
       "      <th>negative loglikelihood</th>\n",
       "      <th>pseudo-R2</th>\n",
       "      <th>stay</th>\n",
       "      <th>switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.900567</td>\n",
       "      <td>15552.488642</td>\n",
       "      <td>0</td>\n",
       "      <td>7735.784630</td>\n",
       "      <td>0.548205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.899150</td>\n",
       "      <td>15451.160951</td>\n",
       "      <td>0</td>\n",
       "      <td>7685.120784</td>\n",
       "      <td>0.551142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.897639</td>\n",
       "      <td>15404.295379</td>\n",
       "      <td>0</td>\n",
       "      <td>7661.687998</td>\n",
       "      <td>0.552520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.900661</td>\n",
       "      <td>15479.462659</td>\n",
       "      <td>0</td>\n",
       "      <td>7699.271638</td>\n",
       "      <td>0.550299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.896223</td>\n",
       "      <td>15319.585616</td>\n",
       "      <td>0</td>\n",
       "      <td>7619.333117</td>\n",
       "      <td>0.554993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.896884</td>\n",
       "      <td>15550.545765</td>\n",
       "      <td>0</td>\n",
       "      <td>7734.813191</td>\n",
       "      <td>0.548142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.899339</td>\n",
       "      <td>15563.425258</td>\n",
       "      <td>0</td>\n",
       "      <td>7741.252938</td>\n",
       "      <td>0.547830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.900189</td>\n",
       "      <td>15562.371937</td>\n",
       "      <td>0</td>\n",
       "      <td>7740.726277</td>\n",
       "      <td>0.547812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.898772</td>\n",
       "      <td>15458.624696</td>\n",
       "      <td>0</td>\n",
       "      <td>7688.852657</td>\n",
       "      <td>0.550987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.906043</td>\n",
       "      <td>15833.470518</td>\n",
       "      <td>0</td>\n",
       "      <td>7876.275568</td>\n",
       "      <td>0.539992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.900472</td>\n",
       "      <td>15548.000739</td>\n",
       "      <td>0</td>\n",
       "      <td>7733.540678</td>\n",
       "      <td>0.548236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.896978</td>\n",
       "      <td>15400.684942</td>\n",
       "      <td>0</td>\n",
       "      <td>7659.882780</td>\n",
       "      <td>0.552651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.899811</td>\n",
       "      <td>15415.392604</td>\n",
       "      <td>0</td>\n",
       "      <td>7667.236610</td>\n",
       "      <td>0.552207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.899245</td>\n",
       "      <td>15449.623860</td>\n",
       "      <td>0</td>\n",
       "      <td>7684.352239</td>\n",
       "      <td>0.551151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.901322</td>\n",
       "      <td>15574.393593</td>\n",
       "      <td>0</td>\n",
       "      <td>7746.737105</td>\n",
       "      <td>0.547475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.897734</td>\n",
       "      <td>15410.567046</td>\n",
       "      <td>0</td>\n",
       "      <td>7664.823832</td>\n",
       "      <td>0.552379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.899150</td>\n",
       "      <td>15391.152607</td>\n",
       "      <td>0</td>\n",
       "      <td>7655.116612</td>\n",
       "      <td>0.552840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.899717</td>\n",
       "      <td>15443.986265</td>\n",
       "      <td>0</td>\n",
       "      <td>7681.533441</td>\n",
       "      <td>0.551288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.899056</td>\n",
       "      <td>15409.563977</td>\n",
       "      <td>0</td>\n",
       "      <td>7664.322297</td>\n",
       "      <td>0.552385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.899433</td>\n",
       "      <td>15481.676218</td>\n",
       "      <td>0</td>\n",
       "      <td>7700.378418</td>\n",
       "      <td>0.550200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.901228</td>\n",
       "      <td>15543.960022</td>\n",
       "      <td>0</td>\n",
       "      <td>7731.520320</td>\n",
       "      <td>0.548335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.903494</td>\n",
       "      <td>15679.265186</td>\n",
       "      <td>0</td>\n",
       "      <td>7799.172902</td>\n",
       "      <td>0.544481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.898961</td>\n",
       "      <td>15468.705152</td>\n",
       "      <td>0</td>\n",
       "      <td>7693.892885</td>\n",
       "      <td>0.550540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.898867</td>\n",
       "      <td>15520.747410</td>\n",
       "      <td>0</td>\n",
       "      <td>7719.914014</td>\n",
       "      <td>0.549138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.900850</td>\n",
       "      <td>15587.465885</td>\n",
       "      <td>0</td>\n",
       "      <td>7753.273251</td>\n",
       "      <td>0.547129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.898111</td>\n",
       "      <td>15365.411192</td>\n",
       "      <td>0</td>\n",
       "      <td>7642.245905</td>\n",
       "      <td>0.553632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.901416</td>\n",
       "      <td>15563.743684</td>\n",
       "      <td>0</td>\n",
       "      <td>7741.412151</td>\n",
       "      <td>0.547825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.895373</td>\n",
       "      <td>15323.435483</td>\n",
       "      <td>0</td>\n",
       "      <td>7621.258050</td>\n",
       "      <td>0.554914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.900472</td>\n",
       "      <td>15485.685882</td>\n",
       "      <td>0</td>\n",
       "      <td>7702.383250</td>\n",
       "      <td>0.550176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.902266</td>\n",
       "      <td>15620.404003</td>\n",
       "      <td>0</td>\n",
       "      <td>7769.742310</td>\n",
       "      <td>0.546264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Condition  Accuracy           BIC  F1  negative loglikelihood  pseudo-R2  \\\n",
       "0       90.0  0.900567  15552.488642   0             7735.784630   0.548205   \n",
       "0       90.0  0.899150  15451.160951   0             7685.120784   0.551142   \n",
       "0       90.0  0.897639  15404.295379   0             7661.687998   0.552520   \n",
       "0       90.0  0.900661  15479.462659   0             7699.271638   0.550299   \n",
       "0       90.0  0.896223  15319.585616   0             7619.333117   0.554993   \n",
       "0       90.0  0.896884  15550.545765   0             7734.813191   0.548142   \n",
       "0       90.0  0.899339  15563.425258   0             7741.252938   0.547830   \n",
       "0       90.0  0.900189  15562.371937   0             7740.726277   0.547812   \n",
       "0       90.0  0.898772  15458.624696   0             7688.852657   0.550987   \n",
       "0       90.0  0.906043  15833.470518   0             7876.275568   0.539992   \n",
       "0       90.0  0.900472  15548.000739   0             7733.540678   0.548236   \n",
       "0       90.0  0.896978  15400.684942   0             7659.882780   0.552651   \n",
       "0       90.0  0.899811  15415.392604   0             7667.236610   0.552207   \n",
       "0       90.0  0.899245  15449.623860   0             7684.352239   0.551151   \n",
       "0       90.0  0.901322  15574.393593   0             7746.737105   0.547475   \n",
       "0       90.0  0.897734  15410.567046   0             7664.823832   0.552379   \n",
       "0       90.0  0.899150  15391.152607   0             7655.116612   0.552840   \n",
       "0       90.0  0.899717  15443.986265   0             7681.533441   0.551288   \n",
       "0       90.0  0.899056  15409.563977   0             7664.322297   0.552385   \n",
       "0       90.0  0.899433  15481.676218   0             7700.378418   0.550200   \n",
       "0       90.0  0.901228  15543.960022   0             7731.520320   0.548335   \n",
       "0       90.0  0.903494  15679.265186   0             7799.172902   0.544481   \n",
       "0       90.0  0.898961  15468.705152   0             7693.892885   0.550540   \n",
       "0       90.0  0.898867  15520.747410   0             7719.914014   0.549138   \n",
       "0       90.0  0.900850  15587.465885   0             7753.273251   0.547129   \n",
       "0       90.0  0.898111  15365.411192   0             7642.245905   0.553632   \n",
       "0       90.0  0.901416  15563.743684   0             7741.412151   0.547825   \n",
       "0       90.0  0.895373  15323.435483   0             7621.258050   0.554914   \n",
       "0       90.0  0.900472  15485.685882   0             7702.383250   0.550176   \n",
       "0       90.0  0.902266  15620.404003   0             7769.742310   0.546264   \n",
       "\n",
       "   stay  switch  \n",
       "0   NaN     NaN  \n",
       "0   NaN     1.0  \n",
       "0   NaN     1.0  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     1.0  \n",
       "0   NaN     NaN  \n",
       "0   NaN     1.0  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     1.0  \n",
       "0   NaN     NaN  \n",
       "0   NaN     1.0  \n",
       "0   NaN     NaN  \n",
       "0   NaN     1.0  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  \n",
       "0   NaN     1.0  \n",
       "0   NaN     1.0  \n",
       "0   NaN     1.0  \n",
       "0   NaN     NaN  \n",
       "0   NaN     NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>7_Reward</th>\n",
       "      <th>6_Reward</th>\n",
       "      <th>5_Reward</th>\n",
       "      <th>4_Reward</th>\n",
       "      <th>3_Reward</th>\n",
       "      <th>2_Reward</th>\n",
       "      <th>1_Reward</th>\n",
       "      <th>1_Port</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.868569</td>\n",
       "      <td>0.608359</td>\n",
       "      <td>0.611786</td>\n",
       "      <td>0.790416</td>\n",
       "      <td>1.204853</td>\n",
       "      <td>1.695804</td>\n",
       "      <td>6.405943</td>\n",
       "      <td>-4.184506</td>\n",
       "      <td>-0.785244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.753657</td>\n",
       "      <td>0.727288</td>\n",
       "      <td>0.730202</td>\n",
       "      <td>0.773412</td>\n",
       "      <td>1.271965</td>\n",
       "      <td>1.663770</td>\n",
       "      <td>6.361293</td>\n",
       "      <td>-4.145239</td>\n",
       "      <td>-0.840181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.840667</td>\n",
       "      <td>0.431029</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>0.864295</td>\n",
       "      <td>1.070663</td>\n",
       "      <td>1.848563</td>\n",
       "      <td>6.396945</td>\n",
       "      <td>-4.154137</td>\n",
       "      <td>-0.847972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.750205</td>\n",
       "      <td>0.606933</td>\n",
       "      <td>0.747629</td>\n",
       "      <td>0.979823</td>\n",
       "      <td>1.018726</td>\n",
       "      <td>1.745885</td>\n",
       "      <td>6.425454</td>\n",
       "      <td>-4.022834</td>\n",
       "      <td>-0.911031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.817203</td>\n",
       "      <td>0.544136</td>\n",
       "      <td>0.819577</td>\n",
       "      <td>0.800489</td>\n",
       "      <td>1.104456</td>\n",
       "      <td>1.927653</td>\n",
       "      <td>6.347736</td>\n",
       "      <td>-4.126152</td>\n",
       "      <td>-0.873987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.681941</td>\n",
       "      <td>0.776425</td>\n",
       "      <td>0.855651</td>\n",
       "      <td>0.600801</td>\n",
       "      <td>1.196681</td>\n",
       "      <td>1.821993</td>\n",
       "      <td>6.291030</td>\n",
       "      <td>-3.762865</td>\n",
       "      <td>-0.975596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.595749</td>\n",
       "      <td>0.706547</td>\n",
       "      <td>0.645877</td>\n",
       "      <td>1.189892</td>\n",
       "      <td>1.791535</td>\n",
       "      <td>6.350515</td>\n",
       "      <td>-4.088492</td>\n",
       "      <td>-0.841021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.733452</td>\n",
       "      <td>0.694560</td>\n",
       "      <td>0.867246</td>\n",
       "      <td>0.827866</td>\n",
       "      <td>1.162312</td>\n",
       "      <td>1.650805</td>\n",
       "      <td>6.341603</td>\n",
       "      <td>-3.826140</td>\n",
       "      <td>-0.968530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.808238</td>\n",
       "      <td>0.722061</td>\n",
       "      <td>0.787417</td>\n",
       "      <td>0.763540</td>\n",
       "      <td>1.183438</td>\n",
       "      <td>1.766629</td>\n",
       "      <td>6.303078</td>\n",
       "      <td>-4.236988</td>\n",
       "      <td>-0.837806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.721550</td>\n",
       "      <td>0.700700</td>\n",
       "      <td>0.615251</td>\n",
       "      <td>0.884618</td>\n",
       "      <td>1.147756</td>\n",
       "      <td>1.618879</td>\n",
       "      <td>6.393617</td>\n",
       "      <td>-3.632884</td>\n",
       "      <td>-1.022584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.799744</td>\n",
       "      <td>0.674932</td>\n",
       "      <td>0.675645</td>\n",
       "      <td>0.735044</td>\n",
       "      <td>1.221442</td>\n",
       "      <td>1.672682</td>\n",
       "      <td>6.419122</td>\n",
       "      <td>-4.350597</td>\n",
       "      <td>-0.732937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.902037</td>\n",
       "      <td>0.567555</td>\n",
       "      <td>0.783815</td>\n",
       "      <td>0.769248</td>\n",
       "      <td>1.254322</td>\n",
       "      <td>1.807442</td>\n",
       "      <td>6.315957</td>\n",
       "      <td>-4.001283</td>\n",
       "      <td>-0.951527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.675587</td>\n",
       "      <td>0.635662</td>\n",
       "      <td>0.918341</td>\n",
       "      <td>1.266846</td>\n",
       "      <td>1.629045</td>\n",
       "      <td>6.408748</td>\n",
       "      <td>-4.143762</td>\n",
       "      <td>-0.853516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.866726</td>\n",
       "      <td>0.621762</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.770957</td>\n",
       "      <td>1.227802</td>\n",
       "      <td>1.708191</td>\n",
       "      <td>6.411419</td>\n",
       "      <td>-3.928801</td>\n",
       "      <td>-0.934323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.721457</td>\n",
       "      <td>0.743472</td>\n",
       "      <td>0.659832</td>\n",
       "      <td>0.843595</td>\n",
       "      <td>1.205529</td>\n",
       "      <td>1.712822</td>\n",
       "      <td>6.317250</td>\n",
       "      <td>-3.999764</td>\n",
       "      <td>-0.890268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.755174</td>\n",
       "      <td>0.659867</td>\n",
       "      <td>0.718399</td>\n",
       "      <td>0.866280</td>\n",
       "      <td>1.151353</td>\n",
       "      <td>1.875370</td>\n",
       "      <td>6.301750</td>\n",
       "      <td>-4.246647</td>\n",
       "      <td>-0.830619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.757710</td>\n",
       "      <td>0.799578</td>\n",
       "      <td>0.676036</td>\n",
       "      <td>0.925762</td>\n",
       "      <td>1.155424</td>\n",
       "      <td>1.658838</td>\n",
       "      <td>6.383303</td>\n",
       "      <td>-4.393156</td>\n",
       "      <td>-0.764855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.756739</td>\n",
       "      <td>0.618244</td>\n",
       "      <td>0.797390</td>\n",
       "      <td>0.742885</td>\n",
       "      <td>1.321229</td>\n",
       "      <td>1.698295</td>\n",
       "      <td>6.382094</td>\n",
       "      <td>-3.915320</td>\n",
       "      <td>-0.934481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.798737</td>\n",
       "      <td>0.700273</td>\n",
       "      <td>0.804084</td>\n",
       "      <td>0.918979</td>\n",
       "      <td>1.190068</td>\n",
       "      <td>1.639198</td>\n",
       "      <td>6.320464</td>\n",
       "      <td>-4.274497</td>\n",
       "      <td>-0.811520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.793920</td>\n",
       "      <td>0.628077</td>\n",
       "      <td>0.652990</td>\n",
       "      <td>0.909763</td>\n",
       "      <td>1.156712</td>\n",
       "      <td>1.815877</td>\n",
       "      <td>6.307153</td>\n",
       "      <td>-4.150430</td>\n",
       "      <td>-0.831992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.733550</td>\n",
       "      <td>0.713032</td>\n",
       "      <td>0.774267</td>\n",
       "      <td>0.766325</td>\n",
       "      <td>1.189326</td>\n",
       "      <td>1.666517</td>\n",
       "      <td>6.367943</td>\n",
       "      <td>-4.206869</td>\n",
       "      <td>-0.787282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.795354</td>\n",
       "      <td>0.800120</td>\n",
       "      <td>0.620395</td>\n",
       "      <td>0.853120</td>\n",
       "      <td>1.028857</td>\n",
       "      <td>1.716089</td>\n",
       "      <td>6.333054</td>\n",
       "      <td>-3.978563</td>\n",
       "      <td>-0.888602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.885155</td>\n",
       "      <td>0.700167</td>\n",
       "      <td>0.687048</td>\n",
       "      <td>0.787473</td>\n",
       "      <td>1.212206</td>\n",
       "      <td>1.666920</td>\n",
       "      <td>6.340160</td>\n",
       "      <td>-4.478314</td>\n",
       "      <td>-0.686640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.754666</td>\n",
       "      <td>0.653353</td>\n",
       "      <td>0.838093</td>\n",
       "      <td>0.820032</td>\n",
       "      <td>1.175668</td>\n",
       "      <td>1.700169</td>\n",
       "      <td>6.306027</td>\n",
       "      <td>-4.048507</td>\n",
       "      <td>-0.871101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.855647</td>\n",
       "      <td>0.694798</td>\n",
       "      <td>0.766637</td>\n",
       "      <td>0.845693</td>\n",
       "      <td>1.179959</td>\n",
       "      <td>1.588266</td>\n",
       "      <td>6.326089</td>\n",
       "      <td>-4.151323</td>\n",
       "      <td>-0.830237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.837410</td>\n",
       "      <td>0.744886</td>\n",
       "      <td>0.702223</td>\n",
       "      <td>0.894830</td>\n",
       "      <td>1.106652</td>\n",
       "      <td>1.663994</td>\n",
       "      <td>6.400116</td>\n",
       "      <td>-4.439074</td>\n",
       "      <td>-0.735055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.823274</td>\n",
       "      <td>0.770527</td>\n",
       "      <td>0.690121</td>\n",
       "      <td>0.804597</td>\n",
       "      <td>0.978963</td>\n",
       "      <td>1.801383</td>\n",
       "      <td>6.366290</td>\n",
       "      <td>-3.929558</td>\n",
       "      <td>-0.929745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.794942</td>\n",
       "      <td>0.664291</td>\n",
       "      <td>0.799156</td>\n",
       "      <td>0.848547</td>\n",
       "      <td>1.201900</td>\n",
       "      <td>1.651923</td>\n",
       "      <td>6.442306</td>\n",
       "      <td>-4.047854</td>\n",
       "      <td>-0.934593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.840835</td>\n",
       "      <td>0.593384</td>\n",
       "      <td>0.796468</td>\n",
       "      <td>0.697442</td>\n",
       "      <td>1.202171</td>\n",
       "      <td>1.827372</td>\n",
       "      <td>6.377820</td>\n",
       "      <td>-3.806397</td>\n",
       "      <td>-1.015202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.660316</td>\n",
       "      <td>0.617189</td>\n",
       "      <td>0.850529</td>\n",
       "      <td>0.811630</td>\n",
       "      <td>1.111969</td>\n",
       "      <td>1.779971</td>\n",
       "      <td>6.343810</td>\n",
       "      <td>-4.146261</td>\n",
       "      <td>-0.840713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Condition  7_Reward  6_Reward  5_Reward  4_Reward  3_Reward  2_Reward  \\\n",
       "0       90.0  0.868569  0.608359  0.611786  0.790416  1.204853  1.695804   \n",
       "0       90.0  0.753657  0.727288  0.730202  0.773412  1.271965  1.663770   \n",
       "0       90.0  0.840667  0.431029  0.820763  0.864295  1.070663  1.848563   \n",
       "0       90.0  0.750205  0.606933  0.747629  0.979823  1.018726  1.745885   \n",
       "0       90.0  0.817203  0.544136  0.819577  0.800489  1.104456  1.927653   \n",
       "0       90.0  0.681941  0.776425  0.855651  0.600801  1.196681  1.821993   \n",
       "0       90.0  0.918478  0.595749  0.706547  0.645877  1.189892  1.791535   \n",
       "0       90.0  0.733452  0.694560  0.867246  0.827866  1.162312  1.650805   \n",
       "0       90.0  0.808238  0.722061  0.787417  0.763540  1.183438  1.766629   \n",
       "0       90.0  0.721550  0.700700  0.615251  0.884618  1.147756  1.618879   \n",
       "0       90.0  0.799744  0.674932  0.675645  0.735044  1.221442  1.672682   \n",
       "0       90.0  0.902037  0.567555  0.783815  0.769248  1.254322  1.807442   \n",
       "0       90.0  0.781609  0.675587  0.635662  0.918341  1.266846  1.629045   \n",
       "0       90.0  0.866726  0.621762  0.698596  0.770957  1.227802  1.708191   \n",
       "0       90.0  0.721457  0.743472  0.659832  0.843595  1.205529  1.712822   \n",
       "0       90.0  0.755174  0.659867  0.718399  0.866280  1.151353  1.875370   \n",
       "0       90.0  0.757710  0.799578  0.676036  0.925762  1.155424  1.658838   \n",
       "0       90.0  0.756739  0.618244  0.797390  0.742885  1.321229  1.698295   \n",
       "0       90.0  0.798737  0.700273  0.804084  0.918979  1.190068  1.639198   \n",
       "0       90.0  0.793920  0.628077  0.652990  0.909763  1.156712  1.815877   \n",
       "0       90.0  0.733550  0.713032  0.774267  0.766325  1.189326  1.666517   \n",
       "0       90.0  0.795354  0.800120  0.620395  0.853120  1.028857  1.716089   \n",
       "0       90.0  0.885155  0.700167  0.687048  0.787473  1.212206  1.666920   \n",
       "0       90.0  0.754666  0.653353  0.838093  0.820032  1.175668  1.700169   \n",
       "0       90.0  0.855647  0.694798  0.766637  0.845693  1.179959  1.588266   \n",
       "0       90.0  0.837410  0.744886  0.702223  0.894830  1.106652  1.663994   \n",
       "0       90.0  0.823274  0.770527  0.690121  0.804597  0.978963  1.801383   \n",
       "0       90.0  0.794942  0.664291  0.799156  0.848547  1.201900  1.651923   \n",
       "0       90.0  0.840835  0.593384  0.796468  0.697442  1.202171  1.827372   \n",
       "0       90.0  0.660316  0.617189  0.850529  0.811630  1.111969  1.779971   \n",
       "\n",
       "   1_Reward    1_Port      Bias  \n",
       "0  6.405943 -4.184506 -0.785244  \n",
       "0  6.361293 -4.145239 -0.840181  \n",
       "0  6.396945 -4.154137 -0.847972  \n",
       "0  6.425454 -4.022834 -0.911031  \n",
       "0  6.347736 -4.126152 -0.873987  \n",
       "0  6.291030 -3.762865 -0.975596  \n",
       "0  6.350515 -4.088492 -0.841021  \n",
       "0  6.341603 -3.826140 -0.968530  \n",
       "0  6.303078 -4.236988 -0.837806  \n",
       "0  6.393617 -3.632884 -1.022584  \n",
       "0  6.419122 -4.350597 -0.732937  \n",
       "0  6.315957 -4.001283 -0.951527  \n",
       "0  6.408748 -4.143762 -0.853516  \n",
       "0  6.411419 -3.928801 -0.934323  \n",
       "0  6.317250 -3.999764 -0.890268  \n",
       "0  6.301750 -4.246647 -0.830619  \n",
       "0  6.383303 -4.393156 -0.764855  \n",
       "0  6.382094 -3.915320 -0.934481  \n",
       "0  6.320464 -4.274497 -0.811520  \n",
       "0  6.307153 -4.150430 -0.831992  \n",
       "0  6.367943 -4.206869 -0.787282  \n",
       "0  6.333054 -3.978563 -0.888602  \n",
       "0  6.340160 -4.478314 -0.686640  \n",
       "0  6.306027 -4.048507 -0.871101  \n",
       "0  6.326089 -4.151323 -0.830237  \n",
       "0  6.400116 -4.439074 -0.735055  \n",
       "0  6.366290 -3.929558 -0.929745  \n",
       "0  6.442306 -4.047854 -0.934593  \n",
       "0  6.377820 -3.806397 -1.015202  \n",
       "0  6.343810 -4.146261 -0.840713  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay_9010 = stats[stats['Condition']==90]['stay'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stay_9010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing beta coefficients across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAEYCAYAAABBWFftAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x734d550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(12,4))\n",
    "gs = gridspec.GridSpec(1,4,width_ratios=[2,1,1,1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "plt.errorbar(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 90].iloc[:,1:].mean(),\n",
    "             yerr= coefs[coefs['Condition'] == 90].iloc[:,1:].mean() / np.sqrt(np.sum(coefs['Condition'] == 90)),\n",
    "             color='red',alpha=0.5)\n",
    "#plt.errorbar(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 80].iloc[:,1:].mean(),\n",
    " #            yerr= coefs[coefs['Condition'] == 90].iloc[:,1:].mean() / np.sqrt(np.sum(coefs['Condition'] == 90)),\n",
    "   #          color='green',alpha=0.5)\n",
    "#plt.errorbar(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 70].iloc[:,1:].mean(),\n",
    " #            yerr= coefs[coefs['Condition'] == 90].iloc[:,1:].mean() / np.sqrt(np.sum(coefs['Condition'] == 90)),\n",
    "  #           color='navy',alpha=0.5)\n",
    "\n",
    "plt.scatter(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 90].iloc[:,1:].mean(),\n",
    "            color='red',label='90-10',s=50)\n",
    "#plt.scatter(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 80].iloc[:,1:].mean(),\n",
    " #           color='green',label='80-20',s=50)\n",
    "#plt.scatter(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 70].iloc[:,1:].mean(),\n",
    " #           color='navy',label='70-30',s=50)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks(np.arange(coefs.shape[1]),coefs.columns.values[1:],rotation='vertical')\n",
    "plt.xlim(-0.5,8.5)\n",
    "plt.title('Regression Coefficients')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "sns.barplot(x='Condition',y='Accuracy',data=stats)\n",
    "plt.title('Accuracy (test)')\n",
    "plt.xticks([0],['90'],fontsize=20)\n",
    "plt.yticks([0.7,0.8,0.9,1.0],fontsize=20)\n",
    "plt.xlabel('Condition',fontsize=20)\n",
    "plt.ylim(0.7,1)\n",
    "\n",
    "plt.subplot(gs[2])\n",
    "sns.barplot(x='Condition',y='F1',data=stats)\n",
    "plt.title('F1 (test)')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(gs[3])\n",
    "sns.barplot(x='Condition',y='pseudo-R2',data=stats)\n",
    "plt.title('pseudo-R2')\n",
    "plt.ylim(0.5,0.8)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAGoCAYAAACwmRWfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xae89400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('white')\n",
    "plt.figure(figsize=(15,6))\n",
    "gs = gridspec.GridSpec(1,2,width_ratios=[3,1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "plt.errorbar(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 90].iloc[:,1:].mean(),\n",
    "             yerr= coefs[coefs['Condition'] == 90].iloc[:,1:].mean() / np.sqrt(np.sum(coefs['Condition'] == 90)),\n",
    "             color='red',alpha=0.5,linewidth=5)\n",
    "#plt.errorbar(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 80].iloc[:,1:].mean(),\n",
    " #            yerr= coefs[coefs['Condition'] == 90].iloc[:,1:].mean() / np.sqrt(np.sum(coefs['Condition'] == 90)),\n",
    "  #           color='green',alpha=0.5,linewidth=5)\n",
    "#plt.errorbar(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 70].iloc[:,1:].mean(),\n",
    " #            yerr= coefs[coefs['Condition'] == 90].iloc[:,1:].mean() / np.sqrt(np.sum(coefs['Condition'] == 90)),\n",
    "  #           color='navy',alpha=0.5,linewidth=5)\n",
    "\n",
    "plt.scatter(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 90].iloc[:,1:].mean(),\n",
    "            color='red',label='90-10',s=100)\n",
    "#plt.scatter(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 80].iloc[:,1:].mean(),\n",
    " #           color='green',label='80-20',s=100)\n",
    "#plt.scatter(np.arange(coefs.shape[1]-1),coefs[coefs['Condition'] == 70].iloc[:,1:].mean(),\n",
    " #           color='navy',label='70-30',s=100)\n",
    "\n",
    "plt.legend(loc='upper left',fontsize=20)\n",
    "plt.xticks(np.arange(coefs.shape[1]),coefs.columns.values[1:],rotation='vertical',fontsize=15)\n",
    "plt.xlabel('')\n",
    "plt.yticks([0,1,2],fontsize=20)\n",
    "plt.ylabel('coefficient value',fontsize=20)\n",
    "plt.xlim(-0.5,8.5)\n",
    "plt.title('Regression Coefficients',fontsize=20)\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "sns.barplot(x='Condition',y='Accuracy',data=stats)\n",
    "plt.title('Accuracy',fontsize=20)\n",
    "plt.xticks([0,1,2],['90','0','0'],fontsize=20)\n",
    "plt.yticks([0.7,0.8,0.9,1.0],fontsize=20)\n",
    "plt.xlabel('Condition',fontsize=20)\n",
    "plt.ylabel('')\n",
    "plt.ylim(0.7,1)\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test number of parameters / model flexibility vs BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = data_80.copy()\n",
    "stats = pd.DataFrame(columns=['Accuracy','BIC','negative loglikelihood','pseudo-R2','No. parameters','F1'])\n",
    "\n",
    "for i,n in enumerate(np.arange(10,0,-1)):\n",
    "    \n",
    "    for j in enumerate(range(30)):\n",
    "        model_curr,stats_curr,coefs_curr = logreg_and_eval(d,num_rewards=n)\n",
    "        models.append(models)\n",
    "        stats_curr['No. parameters'] = n\n",
    "        stats = stats.append(stats_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.factorplot(x='No. parameters',y='BIC',data=stats,color='black')\n",
    "plt.title('BIC vs model flexibility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BIC = np.zeros((10,10))\n",
    "F1 = np.zeros((10,10))\n",
    "R2 = np.zeros((10,10))\n",
    "acc = np.zeros((10,10))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if not ((j==0) & (i==0)):\n",
    "            model_curr,stats_curr,coefs_curr = logreg_and_eval_withports(d,num_rewards=i,num_ports=j)\n",
    "            BIC[i,j] = stats_curr['BIC'].values\n",
    "            F1[i,j] = stats_curr['F1'].values\n",
    "            R2[i,j] = stats_curr['pseudo-R2'].values\n",
    "            acc[i,j] = stats_curr['Accuracy'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.suptitle('Model behavior vs # of rewards and decisions included',x=0.5,y=1.05,fontsize=20)\n",
    "\n",
    "plt.subplot(141)\n",
    "sns.heatmap(BIC,vmin=15000,vmax=25000)\n",
    "plt.xlabel('# previous decisions in model',fontsize=15)\n",
    "plt.ylabel('# previous reward outcomes in model',fontsize=15)\n",
    "plt.title('BIC',fontsize=15)\n",
    "\n",
    "plt.subplot(142)\n",
    "sns.heatmap(F1)\n",
    "plt.xlabel('# previous decisions in model',fontsize=15)\n",
    "plt.ylabel('# previous reward outcomes in model',fontsize=15)\n",
    "plt.title('F1',fontsize=15)\n",
    "\n",
    "plt.subplot(143)\n",
    "sns.heatmap(R2,vmin=0.5)\n",
    "plt.xlabel('# previous decisions in model',fontsize=15)\n",
    "plt.ylabel('# previous reward outcomes in model',fontsize=15)\n",
    "plt.title('R2')\n",
    "\n",
    "plt.subplot(144)\n",
    "sns.heatmap(acc,vmin=0.8)\n",
    "plt.xlabel('# previous decisions in model',fontsize=15)\n",
    "plt.ylabel('# previous reward outcomes in model',fontsize=15)\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training / testing on different conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train on 90-10, test on 80-20 and 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,d in enumerate([data_90,data_80,data_70]):\n",
    "    \n",
    "    if i == 0:\n",
    "        model,stats,coefs = logreg_and_eval(d)\n",
    "    else:\n",
    "        model,stats_curr,coefs_curr = logreg_and_eval(data_90,test_data = d)\n",
    "        \n",
    "        stats = stats.append(stats_curr)\n",
    "        coefs = coefs.append(coefs_curr)\n",
    "\n",
    "stats_90 = stats.drop(['BIC','negative loglikelihood','pseudo-R2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_90['Testing Condition'] = [90,80,70]\n",
    "stats_90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is interesting - accuracy stays pretty much the same across conditions, but F1 goes way down. And if we take a look at the confusion tables above, we can see it is because the accuracy on the switches went down (and accuracy on stays went up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train on 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,d in enumerate([data_80,data_90,data_70]):\n",
    "    \n",
    "    if i == 0:\n",
    "        model,stats,coefs = logreg_and_eval(d)\n",
    "    else:\n",
    "        model,stats_curr,coefs_curr = logreg_and_eval(data_80,test_data = d)\n",
    "        \n",
    "        stats = stats.append(stats_curr)\n",
    "        coefs = coefs.append(coefs_curr)\n",
    "\n",
    "stats_80 = stats.drop(['BIC','negative loglikelihood','pseudo-R2'],axis=1)\n",
    "\n",
    "stats_80['Testing Condition'] = [80,90,70]\n",
    "stats_80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train on 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,d in enumerate([data_70,data_80,data_90]):\n",
    "    \n",
    "    if i == 0:\n",
    "        model,stats,coefs = logreg_and_eval(d)\n",
    "    else:\n",
    "        model,stats_curr,coefs_curr = logreg_and_eval(data_70,test_data = d)\n",
    "        \n",
    "        stats = stats.append(stats_curr)\n",
    "        coefs = coefs.append(coefs_curr)\n",
    "\n",
    "stats_70 = stats.drop(['BIC','negative loglikelihood','pseudo-R2'],axis=1)\n",
    "\n",
    "stats_70['Testing Condition'] = [70,80,90]\n",
    "stats_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1s = np.vstack((stats_90['F1'].values,\n",
    "               stats_80['F1'].values[[1,0,2]],\n",
    "               stats_70['F1'].values[[2,1,0]]))\n",
    "sns.heatmap(f1s,vmin=0,vmax=0.4)\n",
    "plt.xticks([0.5,1.5,2.5],['90','80','70'])\n",
    "plt.yticks([0.5,1.5,2.5],['70','80','90'])\n",
    "plt.ylabel('Testing Condition')\n",
    "plt.xlabel('Training Condition')\n",
    "plt.title('F1 scores when trained & tested on different conditions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if this is right, it means that the rules are different - what predicts a switch in 90-10 does not predict a switch in 80-20. But since most of the trials follow the last one, the accuracy doesn't drop very much. So it appears to be working fine, even though it is not. \n",
    "\n",
    "Can the difference be explained in the small differences in beta coefficient values? It must be ... what else is there? They seem similar enough that I'm surprised it makes such a difference. \n",
    "\n",
    "Let's go on to train and test on separate mice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test on separate mice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's take a quick look at the mice's performances - specifically just at p(choose high P port):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_90.insert(0,'Condition',0.9)\n",
    "data_80.insert(0,'Condition',0.8)\n",
    "data_70.insert(0,'Condition',0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = data_90.append(data_80)\n",
    "all_data = all_data.append(data_70)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x='Condition',y='Higher p port',hue='Mouse ID',data = all_data,legend=False,size=5,aspect=1.7)\n",
    "plt.legend(bbox_to_anchor=(1.2,1))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('Condition',fontsize=20)\n",
    "plt.ylabel('rate higher prob port chosen',fontsize=20)\n",
    "plt.title('Average p(choose better port) for each mouse across conditions',fontsize=20,x=0.5,y=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so based on this. Let's start with 80-20, and do a few different comparisons. \n",
    "\n",
    "1. Start by training with harry, and testing on all the others. \n",
    "2. Then try training on volde, testing on all others. \n",
    "3. Finally train on someone in the middle - like Tom or q45, and test on others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loop through mice\n",
    "'''\n",
    "mice = np.unique(data_80['Mouse ID'].values)\n",
    "\n",
    "stats = pd.DataFrame(columns=['Accuracy','F1','Training Mouse','Testing Mouse'])\n",
    "test_mice = []\n",
    "train_mice = []\n",
    "\n",
    "for mouse_train in mice:\n",
    "\n",
    "    d_train = data_80[data_80['Mouse ID'] == mouse_train].copy()\n",
    "\n",
    "    for i,mouse_test in enumerate(mice):\n",
    "        d_test = data_80[data_80['Mouse ID'] == mouse_test].copy()\n",
    "\n",
    "        if i == 0:\n",
    "            model,stats_curr,coefs = logreg_and_eval(d_train,test_data = d_test)\n",
    "            stats_curr = stats_curr.drop(['BIC','negative loglikelihood','pseudo-R2'],axis=1)\n",
    "            stats = stats.append(stats_curr)\n",
    "        else:\n",
    "            model,stats_curr,coefs_curr = logreg_and_eval(d_train,test_data = d_test)\n",
    "            stats_curr = stats_curr.drop(['BIC','negative loglikelihood','pseudo-R2'],axis=1)\n",
    "            stats= stats.append(stats_curr)\n",
    "            coefs = coefs.append(coefs_curr)\n",
    "\n",
    "        test_mice.append(mouse_test)\n",
    "        train_mice.append(mouse_train)\n",
    "\n",
    "stats['Testing Mouse'] = test_mice\n",
    "stats['Training Mouse'] = train_mice\n",
    "acc_matrix = np.reshape(stats['Accuracy'].values,(len(mice),-1)).T\n",
    "F1_matrix = np.reshape(stats['F1'].values,(len(mice),-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "sns.heatmap(acc_matrix)\n",
    "plt.xticks(np.arange(11)+0.5,mice,rotation='vertical')\n",
    "plt.yticks(np.arange(11)+0.5,mice[::-1],rotation='horizontal')\n",
    "plt.xlabel('Training Mouse')\n",
    "plt.ylabel('Testing Mouse')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.heatmap(F1_matrix)\n",
    "plt.xticks(np.arange(11)+0.5,mice,rotation='vertical')\n",
    "plt.yticks(np.arange(11)+0.5,mice[::-1],rotation='horizontal')\n",
    "plt.xlabel('Training Mouse')\n",
    "plt.ylabel('Testing Mouse')\n",
    "plt.title('F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_80.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_switch = np.zeros(len(mice))\n",
    "u_acc = np.zeros(len(mice))\n",
    "\n",
    "for i,mouse in enumerate(mice):\n",
    "    u_switch[i] = data_80[data_80['Mouse ID']== mouse]['Switch'].mean()\n",
    "    u_acc[i] = data_80[data_80['Mouse ID']== mouse]['Higher p port'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = sns.color_palette('hls',n_colors=len(mice))\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.suptitle('Higher switch rates anti-correlate with accuracy on test mice',fontsize=20,x=0.5,y=1.1)\n",
    "plt.subplot(121)\n",
    "for i,mouse in enumerate(mice):\n",
    "    plt.scatter(u_switch[i],acc_matrix[i,:].mean(),label=mouse,c=colors[i],s=50)\n",
    "#plt.legend(bbox_to_anchor=(1.3,1))\n",
    "plt.xlabel('mean switch rate')\n",
    "plt.ylabel('mean accuracy when used as test mouse')\n",
    "plt.ylim(0.75,1)\n",
    "plt.xlim(0,0.22)\n",
    "plt.title('Testing accuracy vs mean switch rate')\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "for i,mouse in enumerate(mice):\n",
    "    plt.scatter(u_switch[i],acc_matrix[:,i].mean(),label=mouse,c=colors[i],s=50)\n",
    "plt.legend(bbox_to_anchor=(1.3,1))\n",
    "plt.xlabel('mean switch rate')\n",
    "plt.ylabel('mean accuracy when used as train mouse')\n",
    "plt.ylim(0.75,1)\n",
    "plt.xlim(0,0.22)\n",
    "plt.title('Training accuracy vs mean switch rate')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = sns.color_palette('hls',n_colors=len(mice))\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.suptitle('Higher switch rates correlate with F1 score on test mice',fontsize=20,x=0.5,y=1.1)\n",
    "plt.subplot(121)\n",
    "for i,mouse in enumerate(mice):\n",
    "    plt.scatter(u_switch[i],F1_matrix[i,:].mean(),label=mouse,c=colors[i],s=50)\n",
    "#plt.legend(bbox_to_anchor=(1.3,1))\n",
    "plt.xlabel('mean switch rate')\n",
    "plt.ylabel('mean F1 when used as test mouse')\n",
    "#plt.ylim(0.75,1)\n",
    "#plt.xlim(0,0.22)\n",
    "plt.title('Testing F1 vs mean switch rate')\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "for i,mouse in enumerate(mice):\n",
    "    plt.scatter(u_switch[i],F1_matrix[:,i].mean(),label=mouse,c=colors[i],s=50)\n",
    "plt.legend(bbox_to_anchor=(1.3,1))\n",
    "plt.xlabel('mean switch rate')\n",
    "plt.ylabel('mean F1 when used as train mouse')\n",
    "#plt.ylim(0.75,1)\n",
    "#plt.xlim(0,0.22)\n",
    "plt.title('Training F1 vs mean switch rate')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = sns.color_palette('hls',n_colors=len(mice))\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.suptitle('Better behavior correlates with accuracy score on test mice',fontsize=20,x=0.5,y=1.1)\n",
    "plt.subplot(121)\n",
    "for i,mouse in enumerate(mice):\n",
    "    plt.scatter(u_acc[i],acc_matrix[i,:].mean(),label=mouse,c=colors[i],s=50)\n",
    "#plt.legend(bbox_to_anchor=(1.3,1))\n",
    "plt.xlabel('mean p(high p port)')\n",
    "plt.ylabel('mean acc when used as test mouse')\n",
    "#plt.ylim(0.75,1)\n",
    "#plt.xlim(0,0.22)\n",
    "plt.title('Testing Acc vs mean p(high p port)')\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "for i,mouse in enumerate(mice):\n",
    "    plt.scatter(u_acc[i],acc_matrix[:,i].mean(),label=mouse,c=colors[i],s=50)\n",
    "plt.legend(bbox_to_anchor=(1.3,1))\n",
    "plt.xlabel('mean p(high p port)')\n",
    "plt.ylabel('mean acc when used as train mouse')\n",
    "#plt.ylim(0.75,1)\n",
    "#plt.xlim(0,0.22)\n",
    "plt.title('Training acc vs mean p(high p port)')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = sns.color_palette('hls',n_colors=len(mice))\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.suptitle('p(high p port) vs F1 score',fontsize=20,x=0.5,y=1.1)\n",
    "plt.subplot(121)\n",
    "for i,mouse in enumerate(mice):\n",
    "    plt.scatter(u_acc[i],F1_matrix[i,:].mean(),label=mouse,c=colors[i],s=50)\n",
    "#plt.legend(bbox_to_anchor=(1.3,1))\n",
    "plt.xlabel('p(high p port)')\n",
    "plt.ylabel('mean F1 when used as test mouse')\n",
    "#plt.ylim(0.75,1)\n",
    "#plt.xlim(0,0.22)\n",
    "plt.title('Testing F1 vs mean switch rate')\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "for i,mouse in enumerate(mice):\n",
    "    plt.scatter(u_acc[i],F1_matrix[:,i].mean(),label=mouse,c=colors[i],s=50)\n",
    "plt.legend(bbox_to_anchor=(1.3,1))\n",
    "plt.xlabel('p(high p port)')\n",
    "plt.ylabel('mean F1 when used as train mouse')\n",
    "#plt.ylim(0.75,1)\n",
    "#plt.xlim(0,0.22)\n",
    "plt.title('Training F1 vs mean switch rate')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2,interaction_only=True,include_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logreg_and_eval_withports_and_interactions(data,num_rewards=10,num_ports=1,test_data=False):\n",
    "    '''\n",
    "    Perform Logistic Regression on a pandas dataframe of trials (from feature matrix) with interactions\n",
    "    \n",
    "    Inputs:\n",
    "        - data: pandas dataframe of trials (from feature matrix)\n",
    "    Outputs:\n",
    "        - logreg: trained logistic regression model (from sklearn)\n",
    "        - stats:  pandas dataframe with F1, pseudo-R2, and BIC scores from model\n",
    "        - coeffs: beta coefficients from logreg\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    from statsmodels.discrete.discrete_model import Logit\n",
    "    \n",
    "    port_features = []\n",
    "    reward_features = []\n",
    "\n",
    "    #change right port to -1 instead of 0\n",
    "    for col in data:\n",
    "        if '_Port' in col:\n",
    "            data.loc[data[col] == 0,col] = -1\n",
    "            port_features.append(col)\n",
    "        elif '_Reward' in col:\n",
    "            reward_features.append(col)\n",
    "\n",
    "    #create new feature matrix\n",
    "    d = data.copy()\n",
    "    for i in range(len(port_features)):\n",
    "        d[reward_features[i]] = d[reward_features[i]].values*d[port_features[i]].values\n",
    "    \n",
    "    \n",
    "    #determine the features\n",
    "    features = reward_features.copy()\n",
    "    if num_rewards == 0:\n",
    "        features = port_features[-1*num_ports:]\n",
    "    elif num_ports == 0:\n",
    "        features = features[-1*num_rewards:] #only take the num of rewards specificied in the function\n",
    "    else:\n",
    "        features = features[-1*num_rewards:]\n",
    "        features = np.append(features,port_features[-1*num_ports:])\n",
    "    \n",
    "    print(features)\n",
    "    features = np.append(features,'Decision') #finally append the decision so we can take it to predict later\n",
    "    \n",
    "    \n",
    "    \n",
    "    #final version of data\n",
    "    d = d[features].copy() #this now just has the features we want and the decision we want to predict\n",
    "    \n",
    "    #do the same thing for the test data if it exists!\n",
    "    if test_data is not False:\n",
    "        for col in test_data:\n",
    "            if '_Port' in col:\n",
    "                test_data.loc[test_data[col] == 0,col] = -1\n",
    "\n",
    "        #create new feature matrix\n",
    "        data_test_new = test_data.copy()\n",
    "        for i in range(len(port_features)):\n",
    "            data_test_new[reward_features[i]] = test_data[reward_features[i]].values*test_data[port_features[i]].values\n",
    "        \n",
    "        d_test = data_test_new[features].copy()\n",
    "    \n",
    "    \n",
    "        #set training and testing sets now\n",
    "        x_train = d.iloc[:,:-1].values\n",
    "        y_train = d.iloc[:,-1].values\n",
    "        x_test = d_test.iloc[:,:-1].values\n",
    "        y_test = d_test.iloc[:,-1].values\n",
    "        \n",
    "        prev_port_test = test_data['1_Port'].values\n",
    "        prev_port_test[prev_port_test==-1] = 0\n",
    "    \n",
    "    #if there is no test data, then split up the data into training and testing\n",
    "    else:\n",
    "        #extract features and decisions\n",
    "        x = d.iloc[:,:-1].values\n",
    "        y = d.iloc[:,-1].values\n",
    "\n",
    "        #split into training and testing\n",
    "        n_trials = x.shape[0]\n",
    "        shuf_inds = np.random.permutation(n_trials)\n",
    "        split_ind = int(n_trials*0.7)\n",
    "\n",
    "        x_train = x[shuf_inds[:split_ind],:]\n",
    "        y_train = y[shuf_inds[:split_ind]]\n",
    "\n",
    "        x_test = x[shuf_inds[split_ind:],:]\n",
    "        y_test = y[shuf_inds[split_ind:]]\n",
    "        \n",
    "        #extract previous port decision for test set\n",
    "        #these will be used to calculate switches on the test predictions\n",
    "        prev_port_test = data['1_Port'].values[shuf_inds[split_ind:]]\n",
    "        prev_port_test[prev_port_test==-1] = 0\n",
    "    \n",
    "    '''\n",
    "    Modeling\n",
    "    '''\n",
    "    \n",
    "    #create interaction terms\n",
    "    poly = PolynomialFeatures(degree=5,interaction_only=True,include_bias=True)\n",
    "    x_train = poly.fit_transform(x_train)\n",
    "    x_test = poly.fit_transform(x_test)\n",
    "    print('x_train shape: %.0f' % x_train.shape[1])\n",
    "    \n",
    "    \n",
    "    #fit logistic regression\n",
    "    logreg = sklearn.linear_model.LogisticRegressionCV()\n",
    "    logreg.fit(x_train,y_train)\n",
    "    \n",
    "    #predict on testing set\n",
    "    y_predict = logreg.predict(x_test)\n",
    "    y_predict_proba = logreg.predict_proba(x_test)\n",
    "    \n",
    "    #model accuracy\n",
    "    score = logreg.score(x_test,y_test)\n",
    "    \n",
    "    #calculating pseudo-R2 and BIC from statsmodel OLS\n",
    "    model = Logit(y_train,x_train)\n",
    "    rslt  = model.fit()\n",
    "\n",
    "    #switches\n",
    "    y_test_switch = np.abs(y_test - prev_port_test)\n",
    "    y_predict_switch = np.abs(y_predict - prev_port_test)\n",
    "    acc_pos,acc_neg,F1=sf.score_both_and_confuse(y_predict_switch,y_test_switch,confusion=False,disp=True)\n",
    "    \n",
    "    #extract coefficients\n",
    "    coefs = logreg.coef_ #retrieve coefs\n",
    "    coefs = np.append(coefs[0],logreg.intercept_) #add bias coef\n",
    "    \n",
    "    #create stats database to return\n",
    "    d_ = {'pseudo-R2':rslt.prsquared,'stay':acc_pos,'switch':acc_neg,'Accuracy':score,'BIC':rslt.bic,'negative loglikelihood':-1*rslt.llf}\n",
    "    stats = pd.DataFrame(data=d_,index=[0])\n",
    "    features = features[:-1]\n",
    "    features = np.append(features,'Bias')\n",
    "    \n",
    "    #coefs = pd.DataFrame(data=coefs.reshape(1,-1),columns=poly.get_feature_names())\n",
    "    return logreg,stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model,stats_curr = logreg_and_eval_withports_and_interactions(data_80,num_rewards = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.coef_.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(model.coef_.shape[1]),model.coef_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
